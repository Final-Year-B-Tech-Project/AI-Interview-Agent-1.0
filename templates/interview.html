{% extends "base.html" %}

{% block title %}Voice Interview Session - AI Interview Agent{% endblock %}

{% block content %}
<div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-8">
    <div class="grid grid-cols-1 lg:grid-cols-2 gap-8">
        <!-- Left Side - AI Interviewer -->
        <div class="bg-white shadow-lg rounded-lg p-6">
            <div class="mb-6">
                <div class="flex justify-between items-center mb-4">
                    <h2 class="text-xl font-bold text-gray-900">AI Interviewer</h2>
                    <div class="text-sm text-gray-600">
                        <span id="question-counter">Question 1 of 8</span>
                    </div>
                </div>
                
                <!-- Interview Controls -->
                <div class="flex space-x-3 mb-4">
                    <button id="skip-question-btn" class="bg-yellow-600 hover:bg-yellow-700 text-white px-4 py-2 rounded-md font-medium text-sm">
                        ‚è≠Ô∏è Skip Question
                    </button>
                    <button id="end-interview-btn" class="bg-red-600 hover:bg-red-700 text-white px-4 py-2 rounded-md font-medium text-sm">
                        üõë End Interview
                    </button>
                </div>
                
                <!-- Timer -->
                <div class="bg-gray-50 rounded-lg p-3 mb-4">
                    <div class="flex justify-between items-center">
                        <span class="text-sm font-medium text-gray-700">Time Elapsed:</span>
                        <span id="timer" class="text-lg font-bold text-blue-600">00:00</span>
                    </div>
                </div>
            </div>

            <!-- AI Interviewer Avatar -->
            <div class="text-center mb-6">
                <div id="interviewer-avatar" class="w-32 h-32 bg-gradient-to-r from-blue-500 to-purple-600 rounded-full mx-auto flex items-center justify-center mb-4">
                    <svg class="w-16 h-16 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M16 7a4 4 0 11-8 0 4 4 0 018 0zM12 14a7 7 0 00-7 7h14a7 7 0 00-7-7z"/>
                    </svg>
                </div>
                <p id="interviewer-status" class="text-gray-600 text-sm">Ready to begin interview</p>
            </div>

            <!-- Question Display -->
            <div id="question-container" class="mb-6">
                <div id="loading-question" class="text-center py-8">
                    <div class="animate-spin rounded-full h-8 w-8 border-b-2 border-blue-600 mx-auto"></div>
                    <p class="text-gray-600 mt-2">Preparing interview...</p>
                </div>
                
                <div id="question-content" class="hidden">
                    <div class="bg-blue-50 border-l-4 border-blue-400 p-4 mb-4">
                        <div class="flex">
                            <div class="ml-3">
                                <p class="text-sm text-blue-700">
                                    <span id="question-type" class="font-medium"></span> Question
                                    | <span id="question-difficulty" class="font-medium"></span> Level
                                </p>
                            </div>
                        </div>
                    </div>
                    
                    <div class="prose max-w-none">
                        <div id="question-text" class="text-lg text-gray-900 leading-relaxed p-4 bg-gray-50 rounded-lg border-2 border-dashed border-gray-300"></div>
                    </div>
                </div>

                <div id="interview-completed" class="hidden text-center py-8">
                    <div class="text-green-600">
                        <svg class="mx-auto h-12 w-12" fill="none" stroke="currentColor" viewBox="0 0 48 48">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"/>
                        </svg>
                    </div>
                    <h3 class="text-xl font-bold text-gray-900 mt-2">Interview Completed!</h3>
                    <p class="text-gray-600 mt-2">Thank you for completing the voice interview.</p>
                    <button id="view-results-btn" class="mt-4 bg-green-600 hover:bg-green-700 text-white px-6 py-2 rounded-md font-medium">
                        View Results
                    </button>
                </div>
            </div>
        </div>

        <!-- Right Side - Auto Voice Response -->
        <div class="bg-white shadow-lg rounded-lg p-6">
            <div class="mb-4">
                <h3 class="text-lg font-semibold text-gray-900">üé§ Auto Voice Response</h3>
                <p class="text-sm text-green-600 font-medium">Recording starts automatically after AI finishes speaking</p>
            </div>

            <!-- Voice Recording Area -->
            <div id="voice-recording-area" class="border-2 border-dashed border-gray-300 rounded-lg p-8 text-center mb-4">
                <div id="voice-status">
                    <svg class="mx-auto h-16 w-16 text-gray-400 mb-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"/>
                    </svg>
                    <p class="text-gray-600 mb-4">Waiting for AI to finish speaking...</p>
                </div>
            </div>

            <!-- Recording Status -->
            <div id="recording-status" class="text-center mb-4">
                <div id="volume-indicator" class="w-full bg-gray-200 rounded-full h-2 mb-2">
                    <div id="volume-bar" class="bg-green-600 h-2 rounded-full transition-all duration-100" style="width: 0%"></div>
                </div>
                <p id="recording-text" class="text-sm text-gray-600">Ready to record</p>
            </div>

            <!-- Transcribed Answer Display -->
            <div id="transcription-display" class="hidden mt-4 p-4 bg-blue-50 border border-blue-200 rounded-md">
                <h5 class="font-medium text-blue-900 mb-2">Your Voice Answer:</h5>
                <div id="transcribed-text" class="text-sm text-blue-800 bg-white p-3 rounded border min-h-[60px]"></div>
                <div class="mt-3 text-xs text-gray-500">
                    <span id="confidence-score">Confidence: 95%</span> | 
                    <span id="word-count">Words: 0</span>
                </div>
            </div>

            <!-- Answer Feedback -->
            <div id="answer-feedback" class="hidden mt-6 p-4 bg-green-50 border border-green-200 rounded-md">
                <h4 class="font-medium text-green-900">‚úÖ Voice Answer Processed!</h4>
                <p class="text-sm text-green-700 mt-1">Score: <span id="answer-score"></span>/10</p>
                <p class="text-sm text-green-600 mt-2" id="answer-feedback-text"></p>
                <p class="text-xs text-gray-500 mt-3">Moving to next question in 3 seconds...</p>
            </div>
        </div>
    </div>

    <!-- Progress Bar -->
    <div class="mt-8 bg-white shadow rounded-lg p-4">
        <div class="flex justify-between items-center mb-2">
            <span class="text-sm font-medium text-gray-700">Interview Progress</span>
            <span class="text-sm text-gray-600" id="progress-text">0% Complete</span>
        </div>
        <div class="w-full bg-gray-200 rounded-full h-2">
            <div id="progress-bar" class="bg-blue-600 h-2 rounded-full transition-all duration-300" style="width: 0%"></div>
        </div>
    </div>
</div>

<script>
let interviewId = {{ interview.id }};
let currentQuestion = null;
let questionNumber = 0;
let totalQuestions = 8;
let startTime = Date.now();
let questionStartTime = Date.now();
let isRecording = false;
let recognition = null;
let synthesis = window.speechSynthesis;
let currentTranscribedText = "";
let silenceTimer = null;
let voiceStarted = false;

// Voice Activity Detection variables
let audioContext = null;
let microphone = null;
let analyser = null;
let volumeThreshold = 0.01;
let silenceThreshold = 3000; // 3 seconds of silence to auto-submit
let speechTimeout = null;

// Initialize everything
document.addEventListener('DOMContentLoaded', function() {
    setupNaturalSpeech();
    setupAutoVoiceRecording();
    setupEventListeners();
    startTimer();
    startInterviewWithGreeting();
});

function setupNaturalSpeech() {
    // Wait for voices to load
    if (synthesis.getVoices().length === 0) {
        synthesis.addEventListener('voiceschanged', function() {
            console.log('Voices loaded');
        });
    }
}

function setupAutoVoiceRecording() {
    // Check for speech recognition support
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        recognition = new SpeechRecognition();
        
        // Configure for natural conversation
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = 'en-US';
        recognition.maxAlternatives = 1;
        
        recognition.onstart = function() {
            isRecording = true;
            voiceStarted = false;
            updateVoiceStatus('üé§ Listening... Please speak now!', 'recording');
        };
        
        recognition.onresult = function(event) {
            let finalTranscript = '';
            let interimTranscript = '';
            
            for (let i = event.resultIndex; i < event.results.length; i++) {
                const transcript = event.results[i][0].transcript;
                const confidence = event.results[i][0].confidence;
                
                if (event.results[i].isFinal) {
                    finalTranscript += transcript;
                } else {
                    interimTranscript += transcript;
                }
            }
            
            // Update display with real-time transcription
            const fullText = finalTranscript + interimTranscript;
            if (fullText.trim()) {
                voiceStarted = true;
                document.getElementById('transcribed-text').innerHTML = `${finalTranscript}<em>${interimTranscript}</em>`;
                document.getElementById('transcription-display').classList.remove('hidden');
                document.getElementById('word-count').textContent = `Words: ${fullText.split(' ').length}`;
                
                // Reset silence timer when user speaks
                clearTimeout(speechTimeout);
                
                // Set timer to auto-submit after silence
                if (finalTranscript) {
                    speechTimeout = setTimeout(() => {
                        if (isRecording) {
                            stopVoiceRecording();
                            submitVoiceAnswer(finalTranscript);
                        }
                    }, silenceThreshold);
                }
            }
            
            currentTranscribedText = finalTranscript || interimTranscript;
        };
        
        recognition.onerror = function(event) {
            console.error('Speech recognition error:', event.error);
            if (event.error === 'not-allowed') {
                updateVoiceStatus('‚ùå Microphone permission denied', 'error');
            } else {
                updateVoiceStatus('‚ùå Error: ' + event.error, 'error');
            }
        };
        
        recognition.onend = function() {
            isRecording = false;
            if (voiceStarted && currentTranscribedText.trim()) {
                updateVoiceStatus('‚úÖ Processing your answer...', 'processing');
            } else {
                updateVoiceStatus('üé§ Ready for next question', 'ready');
            }
        };
    } else {
        alert('Speech Recognition not supported in this browser. Please use Chrome or Firefox.');
    }
}

function setupEventListeners() {
    document.getElementById('skip-question-btn').addEventListener('click', skipQuestion);
    document.getElementById('end-interview-btn').addEventListener('click', endInterviewEarly);
    document.getElementById('view-results-btn').addEventListener('click', function() {
        window.location.href = `/results/${interviewId}`;
    });
}

function updateVoiceStatus(message, status = 'ready') {
    const statusElement = document.getElementById('voice-status');
    const recordingText = document.getElementById('recording-text');
    
    const statusConfig = {
        'ready': { color: 'text-gray-600', icon: 'M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z' },
        'recording': { color: 'text-red-600', icon: 'M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z' },
        'processing': { color: 'text-blue-600', icon: 'M4 4v5h.582m15.356 2A8.001 8.001 0 004.582 9m0 0H9m11 11v-5h-.581m0 0a8.003 8.003 0 01-15.357-2m15.357 2H15' },
        'error': { color: 'text-red-600', icon: 'M12 8v4m0 4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z' }
    };
    
    const config = statusConfig[status] || statusConfig['ready'];
    
    statusElement.innerHTML = `
        <svg class="mx-auto h-16 w-16 ${config.color} mb-4 ${status === 'recording' ? 'animate-pulse' : ''}" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="${config.icon}"/>
        </svg>
        <p class="${config.color} font-medium">${message}</p>
    `;
    
    recordingText.textContent = message;
}

// Enhanced TTS with natural speech patterns
function speakNaturally(text) {
    if (!synthesis || !text) return Promise.resolve();
    
    return new Promise((resolve) => {
        // Cancel any ongoing speech
        synthesis.cancel();
        
        // Create natural-sounding utterance
        const utterance = new SpeechSynthesisUtterance();
        
        // Make speech more conversational
        const conversationalText = makeConversational(text);
        utterance.text = conversationalText;
        
        // Configure for natural speech
        utterance.rate = 0.85; // Slightly slower for clarity
        utterance.pitch = 0.9; // Slightly lower pitch
        utterance.volume = 1.0;
        
        // Select the most natural voice available
        const voices = synthesis.getVoices();
        const preferredVoice = voices.find(voice => 
            (voice.name.includes('Google') && voice.lang.startsWith('en')) ||
            (voice.name.includes('Microsoft') && voice.lang.startsWith('en') && voice.name.includes('Natural')) ||
            voice.default
        );
        
        if (preferredVoice) {
            utterance.voice = preferredVoice;
        }
        
        utterance.onstart = function() {
            document.getElementById('interviewer-status').textContent = 'Speaking...';
            document.getElementById('interviewer-avatar').classList.add('animate-pulse');
            updateVoiceStatus('üîä AI is asking the question...', 'ready');
        };
        
        utterance.onend = function() {
            document.getElementById('interviewer-status').textContent = 'Waiting for your response...';
            document.getElementById('interviewer-avatar').classList.remove('animate-pulse');
            
            // AUTOMATICALLY START RECORDING after AI finishes speaking
            setTimeout(() => {
                startAutoRecording();
            }, 1000); // Small delay to ensure smooth transition
            
            resolve();
        };
        
        utterance.onerror = function(event) {
            console.error('Speech synthesis error:', event);
            resolve();
        };
        
        synthesis.speak(utterance);
    });
}

function makeConversational(text) {
    // Add natural speech patterns and pauses
    let conversational = text;
    
    // Add natural introductions for questions
    const questionStarters = [
        "Let me ask you this: ",
        "Here's an interesting question for you: ",
        "I'd like to know: ",
        "Tell me about this: ",
        "I'm curious about: "
    ];
    
    if (Math.random() > 0.3) { // 70% chance to add conversational starter
        const starter = questionStarters[Math.floor(Math.random() * questionStarters.length)];
        conversational = starter + conversational;
    }
    
    // Add natural pauses with commas and periods
    conversational = conversational
        .replace(/\. /g, '... ') // Longer pauses after sentences
        .replace(/\? /g, '? ') // Natural pause after questions
        .replace(/: /g, ':... '); // Pause after colons
    
    return conversational;
}

function startAutoRecording() {
    if (!recognition || isRecording) return;
    
    try {
        // Reset transcript display
        document.getElementById('transcribed-text').textContent = 'Starting to listen...';
        document.getElementById('transcription-display').classList.remove('hidden');
        currentTranscribedText = "";
        voiceStarted = false;
        
        recognition.start();
    } catch (error) {
        console.error('Error starting auto recording:', error);
        updateVoiceStatus('‚ùå Could not start auto recording', 'error');
    }
}

function stopVoiceRecording() {
    if (recognition && isRecording) {
        clearTimeout(speechTimeout);
        recognition.stop();
    }
}

async function startInterviewWithGreeting() {
    const greetingMessage = `Hello and welcome! I'm your AI interviewer today. I'll be conducting a comprehensive voice interview to assess your skills and experience. After I ask each question, I'll automatically start recording your response, so just wait for me to finish speaking and then begin your answer. When you stop talking for a few seconds, I'll automatically move to the next question. Are you ready? Let's begin!`;
    
    document.getElementById('interviewer-status').textContent = 'Greeting candidate...';
    
    await speakNaturally(greetingMessage);
    
    setTimeout(() => {
        loadNextQuestion();
    }, 2000);
}

async function loadNextQuestion() {
    try {
        document.getElementById('loading-question').classList.remove('hidden');
        document.getElementById('question-content').classList.add('hidden');
        resetAnswerArea();
        
        const response = await fetch(`/api/interview/${interviewId}/next-question`);
        const data = await response.json();
        
        if (data.completed) {
            showInterviewCompleted(data);
        } else {
            displayQuestion(data);
        }
    } catch (error) {
        console.error('Error loading question:', error);
        alert('Failed to load question. Please refresh the page.');
    }
}

function displayQuestion(data) {
    currentQuestion = data.question;
    questionNumber = data.question_number;
    questionStartTime = Date.now();
    
    // Update UI
    document.getElementById('question-text').textContent = currentQuestion.text;
    document.getElementById('question-type').textContent = currentQuestion.type;
    document.getElementById('question-difficulty').textContent = currentQuestion.difficulty;
    document.getElementById('question-counter').textContent = `Question ${questionNumber} of ${totalQuestions}`;
    
    // Update progress
    const progress = (questionNumber / totalQuestions) * 100;
    document.getElementById('progress-bar').style.width = progress + '%';
    document.getElementById('progress-text').textContent = Math.round(progress) + '% Complete';
    
    // Show question
    document.getElementById('loading-question').classList.add('hidden');
    document.getElementById('question-content').classList.remove('hidden');
    
    // Speak question naturally (this will auto-start recording when done)
    setTimeout(() => {
        speakNaturally(currentQuestion.text);
    }, 1000);
}

async function submitVoiceAnswer(answerText) {
    if (!answerText.trim()) {
        updateVoiceStatus('‚ùå No speech detected. Moving to next question...', 'error');
        setTimeout(loadNextQuestion, 2000);
        return;
    }
    
    updateVoiceStatus('üîÑ Processing your answer...', 'processing');
    
    try {
        const timeTaken = Math.round((Date.now() - questionStartTime) / 1000);
        
        const response = await fetch(`/api/interview/${interviewId}/submit-answer`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                question_id: currentQuestion.id,
                answer_text: answerText,
                time_taken_seconds: timeTaken
            })
        });
        
        const result = await response.json();
        
        if (response.ok) {
            // Show feedback
            document.getElementById('answer-score').textContent = result.score;
            document.getElementById('answer-feedback-text').textContent = result.feedback;
            document.getElementById('answer-feedback').classList.remove('hidden');
            
            // Auto-advance to next question
            setTimeout(loadNextQuestion, 3000);
        } else {
            alert('Error submitting answer: ' + result.error);
        }
    } catch (error) {
        console.error('Error:', error);
        alert('Failed to submit answer. Moving to next question.');
        setTimeout(loadNextQuestion, 2000);
    }
}

function resetAnswerArea() {
    document.getElementById('transcription-display').classList.add('hidden');
    document.getElementById('answer-feedback').classList.add('hidden');
    document.getElementById('transcribed-text').textContent = '';
    currentTranscribedText = "";
    updateVoiceStatus('üé§ Ready for next question', 'ready');
}

async function skipQuestion() {
    if (confirm('Skip this question? This will affect your score.')) {
        stopVoiceRecording();
        await submitVoiceAnswer("Question skipped by candidate");
    }
}

async function endInterviewEarly() {
    if (confirm('End interview early? You will receive results based on answered questions.')) {
        stopVoiceRecording();
        try {
            const response = await fetch(`/api/interview/${interviewId}/end-early`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' }
            });
            
            if (response.ok) {
                const data = await response.json();
                showInterviewCompleted(data);
            }
        } catch (error) {
            console.error('Error ending interview:', error);
            window.location.href = `/results/${interviewId}`;
        }
    }
}

function showInterviewCompleted(data) {
    stopVoiceRecording();
    
    document.getElementById('loading-question').classList.add('hidden');
    document.getElementById('question-content').classList.add('hidden');
    document.getElementById('interview-completed').classList.remove('hidden');
    
    // Update progress to 100%
    document.getElementById('progress-bar').style.width = '100%';
    document.getElementById('progress-text').textContent = '100% Complete';
    
    // Speak completion message
    const completionMessage = `Congratulations! You have successfully completed your voice interview. Your overall performance score is ${data.overall_score} out of 10. You can now view your detailed results and feedback. Thank you for participating!`;
    speakNaturally(completionMessage);
}

function startTimer() {
    setInterval(function() {
        const elapsed = Math.floor((Date.now() - startTime) / 1000);
        const minutes = Math.floor(elapsed / 60);
        const seconds = elapsed % 60;
        document.getElementById('timer').textContent = 
            String(minutes).padStart(2, '0') + ':' + String(seconds).padStart(2, '0');
    }, 1000);
}
</script>
{% endblock %}
